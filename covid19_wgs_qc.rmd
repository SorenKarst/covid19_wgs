---
title: "COVID-19 WGS QC"
output:
  html_document:
    fig_caption: yes
---

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(ggsci)
library(cowplot)
library(kableExtra)
library(DT)
library(ggtree)
library(Biostrings)
options(scipen=999)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Load data for testing purposes
use_preprocessed_data <- !file.exists("data.RData")
if(file.exists("data.RData")){
  load("data.RData")
}
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Report settings
batch_dir <- rstudioapi::selectDirectory(path = getwd())
yield_filter_factor <- 5
hq_n <- 200
mq_n <- 6000
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Import metadata
m <- read_tsv(
  "metadata.tsv"
) %>%
  mutate(
    sample_category = ifelse(grepl("nc_|pc_", str_to_lower(sample_name)), "control", "sample"),
  ) 

batch_list <- 
  m$batch %>%
  unique()
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Import coverage data

# Column names
pcc <- c(
  "barcode_id",
  "ref",
  "start",
  "end",
  "amplicon_id",
  "pool_id",
  "strand",
  "amplicon_pos",
  "coverage"
)

# List of coverage files
pcl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "coverage.tsv",
  recursive = T,
  full.names = T
) %>%
  set_names(., sub("/coverage.tsv", "", .) %>% gsub(".*/", "", .))

# Import and format coverage files
# Coverage tallys is pr. amplicon. Due to tiled amplicon setup overlapping positions are tallied twice.
pc <- 
  pcl %>%
  lapply(
    .,
    function(file){read_tsv(file, col_names = pcc)} %>%
      mutate(
        amplicon_id = gsub("SARS-CoV-2_INSERT_", "", amplicon_id) %>% as.integer()
      )
  ) %>%
  bind_rows(
    .id = "batch"
  ) %>%
  transmute(
    batch,
    barcode_id,
    start,
    end,
    amplicon_id,
    pool_id,
    position = start + amplicon_pos - 1,
    coverage
  )

# Calculate reference length
ref_length <- max(pc$end) - min(pc$start)

# Position-wise coverage
# Ensure no duplicated positions and calculate position wise normalized coverage 
pcn <- 
  pc %>%
  group_by(batch, barcode_id, position) %>%
  summarise(
    coverage = mean(coverage),
    amplicon_ol = paste(amplicon_id, sep = ";", collapse = ";")
  ) %>%
  group_by(batch, barcode_id) %>%
  mutate(
    cov_norm = coverage/sum(coverage)*(max(position)-min(position))
  )

# Amplicon-wise coverage
# Remove both duplicated positions and calculate amplicon wise mean and normalized coverage 
acn <-
  pc %>%
  group_by(batch, barcode_id, position) %>%
  filter(n() == 1) %>%
  group_by(batch, barcode_id, amplicon_id) %>%
  summarise(
    cov_total = sum(coverage),
    start = min(position),
    end = max(position)
  ) %>%
  group_by(batch, barcode_id) %>%
  mutate(
    cov_mean = cov_total/(end-start),
    cov_norm = cov_total/sum(cov_total) * n()
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Import nextclade classification
nl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "nextclade.tsv",
  recursive = T,
  full.names = T
  ) %>%
   set_names(., sub("/nextclade.tsv", "", .) %>% gsub(".*/", "", .))

n <- 
  nl %>%
  lapply(
    .,
    function(file){read_tsv(file)}
  ) %>%
  bind_rows(
    .id = "batch"
  ) %>%
  mutate(
    barcode_id = gsub("/.*", "", seqName), 
  ) %>%
  transmute(
    batch,
    barcode_id,
    classification = gsub(".*\\(|\\)|,.*", "", clade),
    substitutions,
    deletions,
    insertions,
    n_count = totalMissing,
    nxcl_quality = qc.overallStatus,
    missing
  ) %>%
  {
    ntbl <- .
    left_join(
      ntbl,
      ntbl$missing %>%
        str_split(",") %>%
        set_names(paste(ntbl$batch, ntbl$barcode_id, sep = ";")) %>%
        lapply(
          function(m){
            tibble(miss_range = m)
          }
        ) %>%
        bind_rows(.id = "id") %>%
        mutate(
          start = str_split(miss_range, "-") %>%
            lapply(., function(x){as.integer(x) %>% min()}) %>% unlist(),
          end = str_split(miss_range, "-") %>%
            lapply(., function(x){as.integer(x) %>% max()}) %>% unlist(),
        ) %>%
        group_by(id) %>%
        filter(end - start + 1 < 3) %>%
        summarise(
          mixed_n = n(),
          mixed_position = paste(miss_range, collapse = ",")
        ) %>%
        ungroup() %>%
        separate(
          id,
          c("batch", "barcode_id"),
          ";"
        ),
      by = c("batch", "barcode_id")
    )
  } %>%
  {
    ntbl <- .
    left_join(
      ntbl,
      ntbl$missing %>%
        str_split(",") %>%
        set_names(paste(ntbl$batch, ntbl$barcode_id, sep = ";")) %>%
        lapply(
          function(m){
            tibble(miss_range = m)
          }
        ) %>%
        bind_rows(.id = "id") %>%
        mutate(
          start = str_split(miss_range, "-") %>%
            lapply(., function(x){as.integer(x) %>% min()}) %>% unlist(),
          end = str_split(miss_range, "-") %>%
            lapply(., function(x){as.integer(x) %>% max()}) %>% unlist(),
        ) %>%
        group_by(id) %>%
        filter(end - start + 1 >= 3) %>%
        summarise(
          missing_position = paste(miss_range, collapse = ",")
        ) %>%
        ungroup() %>%
        separate(
          id,
          c("batch", "barcode_id"),
          ";"
        ),
      by = c("batch", "barcode_id")
    )
  } %>%
  left_join(
    m,
    .,
    by = c("barcode_id", "batch")
  ) %>%
  mutate(
    n_quality =
      case_when(
        grepl("nc", str_to_lower(sample_name)) & n_count/ref_length < 0.25 ~ "NC_fail",
        grepl("nc", str_to_lower(sample_name)) & (n_count/ref_length >= 0.25 | is.na(n_count))~ "NC_pass",
        is.na(n_count) ~ "missing_filter",
        n_count <= hq_n ~ "HQ",
        n_count <= mq_n ~ "MQ",
        T ~ "n_filter"
      ),
    mixed_quality = 
      case_when(
        mixed_n > 3 ~ "mixed_filter",
        is.na(nxcl_quality) ~ as.character(NA), 
        T ~ "pass"
      )
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Pangolin lineage
pl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "pangolin.csv",
  recursive = T,
  full.names = T
  ) %>%
   set_names(., sub("/pangolin.csv", "", .) %>% gsub(".*/", "", .))

p <- 
  pl %>%
  lapply(
    .,
    function(file){read_csv(
      file
      )}
  ) %>%
  bind_rows(
    .id = "batch"
  ) %>%
  mutate(
    barcode_id = gsub("/.*", "", taxon), 
  ) %>%
  select(
    batch,
    barcode_id,
    pango_lineage = lineage,
    scorpio_lineage = scorpio_call
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Yield over time
ytl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "yield.tsv",
  recursive = T,
  full.names = T
  ) %>%
  set_names(., sub("/yield.tsv", "", .) %>% gsub(".*/", "", .))

yt <- 
  ytl %>%
  lapply(
    .,
    function(file){read_tsv(file)}
  ) %>%
  bind_rows(
    .id = "batch"
  ) %>%
  full_join(
    m %>% select(batch, barcode_id, sample_name, sample_category),
    .,
    by = c("batch", "barcode_id")
  ) %>%
  mutate(
    reads_n = ifelse(is.na(reads_n), 0, reads_n),
    yield_bp = ifelse(is.na(yield_bp), 0, yield_bp),
    date_time = as_datetime(date_time)
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Length distribution
ll <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "length.tsv",
  recursive = T,
  full.names = T
  ) %>%
  set_names(., sub("/length.tsv", "", .) %>% gsub(".*/", "", .))

l <- 
  ll %>%
  lapply(
    .,
    function(file){read_tsv(file)}
  ) %>%
  bind_rows(
    .id = "batch"
  ) %>%
  mutate(
    barcode_classification = case_when(
      barcode_id == "unclassified" ~ "None",
      paste(batch, barcode_id, sep = "_") %in% paste(m$batch, m$barcode_id, sep = "_") ~ "Used",
      T ~ "Unused"
    )
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Import trees
tl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "consensus_tree.nwk",
  recursive = T,
  full.names = T
  ) %>%
  set_names(., sub("/consensus_tree.nwk", "", .) %>% gsub(".*/", "", .))

tree <- 
  tl %>%
  lapply(
    .,
    function(file){
      tree <- read.tree(file)
      tree$tip.label <- sub("/.*", "", tree$tip.label)
      return(tree)
      }
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
#Import consensus sequences
sl <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "^consensus.fa",
  recursive = T,
  full.names = T
  ) %>%
  set_names(., sub("/consensus.fa", "", .) %>% gsub(".*/", "", .))

s <- 
  sl %>%
  lapply(
    .,
    function(file){
      seq <- readDNAStringSet(file)
      names(seq) <- names(seq) %>%
        gsub("/.*", "", .)
      return(seq)
      }
  ) %>%
  DNAStringSetList() %>%
  unlist()
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
#Import consensus sequences
spec_l <- list.files(
  path = paste(batch_dir, "/", batch_list, sep = ""),
  pattern = "^specifications.tsv",
  recursive = T,
  full.names = T
  ) %>%
  set_names(., sub("/specifications.tsv", "", .) %>% gsub(".*/", "", .))

spec <- 
  spec_l %>%
  lapply(
    .,
    function(file){read_tsv(file)}
  ) %>%
  bind_rows(
    .id = "batch"
  )

spec_v <-
  spec %>%
  filter(
    process %in% c("bioinformatics_protocol", "pangolin","pangolearn","nextclade")
  ) %>%
  select(process, version_available) %>%
  mutate(version_nr = parse_number(version_available %>% gsub("-", "", .))) %>%
  group_by(process) %>%
  slice_max(
    order_by = version_nr, n = 1, with_ties = F
  ) %>%
  select(-version_nr) %>%
  spread(
    key = "process",
    value = "version_available"
  ) %>%
  mutate(
    batch = "version_available",
    flowcell_id = "",
    start_date = ""
  )
 
spec_s <-
  spec %>%
  filter(
    process %in% c("bioinformatics_protocol", "pangolin","pangolearn","nextclade")
  ) %>%
  select(-version_available) %>%
  spread(
    key = "process",
    value = "version_used"
  )
```

```{r message=FALSE, warning=FALSE, include=FALSE, eval = use_preprocessed_data}
# Store data for testing purposes
# save.image(file = "data.RData")
```

## Run specifications summary

---

Summary of sequencing batches processed for QC and versions of key software packages used for processing. Ensure correct sequencing runs have been included in the analysis and ensure software versions are not out of date.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, echo=FALSE}
yts <-
  yt %>%
  group_by(batch, flowcell_id) %>%
  summarise(
    start_date = min(date_time) %>% gsub(" .*", "", .)
  ) %>%
  group_by(batch) %>%
  summarise(
    flowcell_id = paste(unique(flowcell_id), collapse = ";"),
    start_date = paste(start_date, collapse = ";")
  ) %>%
  gather(
    key = "process",
    value = "value",
    2:3
  ) %>%
  spread(
    key = "process",
    value = "value"
  )

spec_s %>%
  left_join(
    yts,
    .,
    by = "batch"
  ) %>%
  bind_rows(spec_v) %>%
  kbl() %>%
  kable_minimal(c("hover"))
```


&nbsp;
&nbsp;
&nbsp;
&nbsp;


## Sequencing summary

---

Summary sequencing yield, yield over time, number of reads and read distribution. Expected sequencing yield from a MinION flowcell is 5-15 Gbp if run for 72 hrs (4320 min). Read length distribution depends on protocol type, but will either be a continuous distribution (fragmentation library preparation) or a single peak (ligation library preparation) between 200 and 1200 bp. Large fraction of unused data indicates incomplete sample assignment in the metadata sheet or barcode contamination.


&nbsp;
&nbsp;
&nbsp;
&nbsp;


```{r message=FALSE, warning=FALSE, include=FALSE}
# Yield time statistics
yt_start <-
  yt %>%
  group_by(batch) %>%
  summarise(
    start_time = min(date_time, na.rm = T) %>%
      as_datetime()
  )

ytc <- 
  yt %>%
  left_join(yt_start, by = "batch") %>%
  mutate(
    barcode_classification = case_when(
      barcode_id == "unclassified" ~ "None",
      paste(batch, barcode_id, sep = "_") %in% paste(m$batch, m$barcode_id, sep = "_") ~ "Used",
      T ~ "Unused"
    ),
    date_time = if_else(is.na(date_time), start_time, date_time)
  ) %>%
  group_by(batch, barcode_classification) %>%
  arrange(date_time) %>%
  mutate(
    cum_reads_n = cumsum(reads_n),
    cum_yield_bp = cumsum(yield_bp),
    minutes = (date_time - start_time) %>% as.integer(.)/60
  )
```

```{r fig.cap="\\label{fig:seq_summary_tab} Sequencing summary", message=FALSE, warning=FALSE, echo=FALSE}
# Compile sequencing summary table
seqsum_t1 <-
  ytc %>%
  group_by(batch) %>%
  summarise(
    yield_total = (sum(yield_bp)/1000000000) %>% round(1),
    yield_used_bp = (sum(ifelse(barcode_id %in% m$barcode_id, yield_bp, 0))/1000000000) %>% round(1),
    yield_unused_bp = (sum(ifelse(!(barcode_id %in% c(m$barcode_id, "unclassified")), yield_bp, 0))/1000000000) %>% round(1),
    yield_none_bp = (sum(ifelse(barcode_id == "unclassified", yield_bp, 0)/1000000000)) %>% round(1),
    yield_pr_sample_bp = NA,
    total_reads_n = (sum(reads_n)/1000000) %>% round(1),
    duration = max(minutes) - min(minutes)
  ) %>%
  ungroup() %>%
  set_names(c("Batch", "Yield total (Gbp)", "Yield used barcodes (Gbp)", "Yield unused barcodes (Gbp)", "Yield none barcodes (Gbp)","Yield pr. sample (Mbp)", "Total reads (mio)", "Duration (min)")) %>%
  left_join(
    m %>%
      group_by(batch, sample_category) %>%
      summarise(samples_n = n()) %>%
      spread(key = sample_category, value = samples_n) %>%
      {if("sample" %in% names(.)) . else {mutate(., sample = 0)}} %>%
      {if("control" %in% names(.)) . else {mutate(., control = 0)}}  %>%
      dplyr::rename(`Batch` = batch, `Samples (n)` = sample, `Controls (n)` = control),
    by = "Batch"
  ) %>%
  mutate(
    `Yield pr. sample (Mbp)` =
      (`Yield used barcodes (Gbp)`/(`Samples (n)` + `Controls (n)`)*1000) %>%
      round(1),
    yield_check = ifelse(
      `Yield used barcodes (Gbp)`/(`Samples (n)` + `Controls (n)`) > 0.06,
      "white",
      "#DC0000B2"
      ),
    unused_check = ifelse(
      `Yield unused barcodes (Gbp)`/`Yield total (Gbp)` < 0.01,
      "white",
      "#DC0000B2"
      ),
    none_check = ifelse(
      `Yield none barcodes (Gbp)`/`Yield total (Gbp)` < 0.5,
      "white",
      "#DC0000B2"
      )
  ) %>%
  {
    tbl <- .
    kbl(tbl %>% select(-yield_check, -unused_check, -none_check)) %>%
      kable_minimal(c("hover")) %>%
      column_spec(
        4,
        background = tbl$unused_check
      ) %>%
      column_spec(
        5,
        background = tbl$none_check
      ) %>%
      column_spec(
        6,
        background = tbl$yield_check
      )
  } %>%
  kableExtra::footnote(
    general = "Yield pr. sample should be > 60 Mbp/sample (> 2000x).", escape = FALSE 
  )

seqsum_t1
```

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r yield_plot, fig.cap="\\label{fig:seq_summary_plot} Cumulative Demultiplexed sequencing yield over duration of run", message=FALSE, warning=FALSE, echo=FALSE}
# Yield over time plot
seqsum_p1 <- 
  ggplot(
  ytc,
  aes(
    x = minutes,
    y = cum_yield_bp/1000,
    color = barcode_classification
  )
) + 
  geom_line() +
  scale_color_npg() +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(
    y = "Yield (Gbp)",
    x = "Time (minutes)",
    color = "Barcode"
  ) +
  facet_grid(
    rows = vars(batch)
  )
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Length distribution plot
seqsum_p2 <-
  ggplot(
    l,
    aes(
      x = length_bp,
      y = count,
      fill = barcode_classification
    )
  ) + 
  geom_col() +
  scale_fill_npg() +
  theme_classic() +
  xlim(0, 2000) +
  theme(legend.position = "bottom") +
  labs(
    y = "Count (n)",
    x = "Fragment length (bp)",
    fill = "Barcode"
  ) +
  facet_grid(
    rows = vars(batch)
  )
  
```

```{r message=FALSE, warning=FALSE, echo=FALSE, out.width = "100%"}
# Combine plots
plot_grid(
  seqsum_p1,
  seqsum_p2,
  ncol = 2,
  align = 'v',
  axis = 'lr'
  )
```

**Data categories**

* Used:   Data assigned to barcode IDs in the metadata sheet.
* Unused: Data assigned to barcodes IDs not in the metadata sheet.
* None:   Data not assigned to a barcode.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

## QC summary

---

Summary of the QC status of each sample. Samples are classified according to the quality of the consensus genome generated from the sample data and the performance of the negative controls (NC). Important: Negative controls should be flagged in the metadata column sample_name with the post-fix `nc_*` eg. `nc_ext1` or `nc_pcr2`. Passing samples and genomes are assigned as `HQ` or `MQ`, where failing samples are assigned with the filter causing the sample to fail. The filter definitions can be seen below.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
# Calculate yield (BP) and define filter settings
y <-
  pcn %>%
  group_by(barcode_id, batch) %>%
  summarise(
    yield_bp = sum(coverage)
    ) %>%
  left_join(
    n,
    .,
    by = c("batch", "barcode_id")
  ) %>%
  left_join(
    p,
    by = c("batch", "barcode_id") 
  ) %>%
  mutate(
    rep = 1:n(),
    yield_bp = ifelse(is.na(yield_bp), as.numeric(0), yield_bp)
  )

ytcf <- 
  ytc %>%
  group_by(batch, barcode_id, barcode_classification) %>%
  summarise(
    total_yield_bp = (sum(yield_bp)) %>% round(1),
    total_reads_n = (sum(reads_n)) %>% round(1),
  ) %>%
  filter(
    barcode_classification == "Unused"
  ) %>%
    group_by(
    batch
  ) %>%
  slice_max(
    total_yield_bp,
    n = 1
    ) %>%
  mutate(
    yield_cutoff_unused = total_yield_bp * yield_filter_factor
  ) %>%
  {if(nrow(.) == 0){
    tibble(
      batch = unique(ytc$batch),
      yield_cutoff_unused = 0
    )
  } else .}

yc <- 
  y %>%
  filter(
    sample_category == "control",
    grepl("nc_", str_to_lower(sample_name)),
    !is.na(n_count)
  ) %>%
  group_by(
    batch
  ) %>%
  slice_max(
    yield_bp,
    n = 1
  ) %>%
  mutate(
    yield_cutoff = yield_bp * yield_filter_factor
  ) %>%
  {if(nrow(.) == 0){
    tibble(
      batch = unique(y$batch),
      yield_cutoff = 0
    )
  } else .}


ycm <- 
  bind_rows(
    yc %>% select(batch, barcode_id, sample_name, yield_bp, yield_cutoff),
    ytcf %>% select(batch, barcode_id, yield_bp = total_yield_bp, yield_cutoff = yield_cutoff_unused)
  ) %>%
  group_by(batch) %>%
  slice_max(
    order_by = yield_cutoff,
    n = 1,
    with_ties = F
  )



yf <- 
  y %>%
  left_join(
    ycm %>% select(batch, yield_cutoff),
    by = "batch"
  ) %>%
  mutate(
    filter = 
      case_when(
        grepl("nc_", str_to_lower(sample_name)) ~ n_quality,
        n_quality == "missing_filter" ~ "missing_filter",
        yield_bp < yield_cutoff ~ "yield_filter",
        mixed_n > 3 ~ "mix_filter",
        yield_bp >= yield_cutoff ~ n_quality,
        is.na(yield_cutoff) ~ n_quality
      )
  )

yfl <- c("HQ", "MQ", "n_filter", "missing_filter", "mix_filter", "yield_filter", "NC_fail", "NC_pass")
yfc <- c("#00A087FF", "#4DBBD5FF", "#F39B7FFF", "gray85", "gray75", "gray55", "deeppink", "mediumpurple1")
yfo <- 
  tibble(
    levels = yf$batch,
    order = parse_number(yf$batch)
  ) %>%
  arrange(order) %>%
  .$levels %>%
  unique()
```

```{r message=FALSE, warning=FALSE, include=FALSE}
cp1 <- ggplot(
  yf,
  aes(
    "Samples",
    yield_bp/1000000,
    color = filter
  )
) +
  geom_jitter(width = 0.05) +
  geom_point(
    data = ycm,
    aes(
      x = "Samples",
      y = yield_cutoff/1000000
    ),
    shape=95,
    size=10,
    color = "black"
  ) +
  facet_grid(
    factor(
      batch,
      levels = yfo)~.
      ) +
  scale_y_log10() +
  scale_color_manual(
    values = yfc,
    breaks = yfl
    ) +
  labs(
    x = NULL,
    y = "Yield (Mbp)",
    color = "QC filter"
  ) +
  theme(legend.position = "none") 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
qp1 <- ggplot(
  yf,
  aes(
    "Samples",
    fill = factor(filter, levels = rev(yfl))
  )
) +
  geom_bar() +
  geom_text(
    aes(
      label = ..count..
      ),
    stat = "count",
    colour = "white",
    position=position_stack(vjust=0.5)
    ) +
  facet_grid(
    factor(
      batch,
      levels = yfo)~.
      ) +
  scale_fill_manual(
    values = yfc,
    breaks = yfl,
    drop = FALSE
  ) +
  labs(
    x = NULL,
    y = "Number of samples",
    fill = "QC filter"
  )
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
yf %>%
  filter(sample_category != "control") %>%
  mutate(
    success = 
      case_when(
        filter == "HQ" ~ "HQ",
        filter == "MQ" ~ "MQ",
        T ~ "Fail"
      )
  ) %>%
  group_by(batch, success) %>%
  summarise(
    n = n()
  ) %>%
  ungroup() %>%
  mutate(
    success = factor(success, levels = c("HQ", "MQ", "Fail"))
  ) %>%
  spread(
    key = "success",
    value = "n",
    drop = F,
    fill = 0
  ) %>%
  mutate(
    `Genome success (%)` = round(HQ + MQ/(HQ+MQ+Fail)*100, 0)
  ) %>%
  kbl() %>%
  kable_minimal(c("hover"))
  
```

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r qc_summary_plot, message=FALSE, warning=FALSE, echo=FALSE, out.width = "100%"}
cpqp1 <- plot_grid(
  cp1,
  qp1,
  ncol = 2,
  align = 'v',
  axis = 'lr'
  )

cpqp1
```

**Filters**

|   |   |
|---|---|
|HQ|< `r hq_n` N|
|MQ|< `r mq_n` N|
|n_filter|>= `r mq_n` N|
|yield_filter|sample yield < `r yield_filter_factor`x negative control/unused (max)|
|missing_filter|No aligned genome (missing or poor quality)|
|mix_filter|> 3 ambiguous bases|
|NC_pass|< 75% genome coverage|
|NC_fail|> 75% genome coverage|
|   |   |

&nbsp;
&nbsp;
&nbsp;
&nbsp;

**Barcode IDs used for yield cut-off**

```{r message=FALSE, warning=FALSE, echo=FALSE,}
ycm %>%
  mutate(
    sample_name = ifelse(is.na(sample_name), "Unused", sample_name)
  ) %>%
    kbl() %>%
    kable_minimal(c("hover")) 
```

&nbsp;
&nbsp;
&nbsp;
&nbsp;

## Sample summary list

---

Summary list of all samples in the QC report. The list can be filtered and is searchable. For example search "`[batch_id]` Unused", to show all unused barcodes with data in a specific batch. The columns can be sorted by presseing the small arrows next to the column names.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Barcode sample list
seqsum_t2 <-
  ytc %>%
  group_by(batch, barcode_id, barcode_classification) %>%
  summarise(
    total_yield_bp = (sum(yield_bp)/1000000) %>% round(1),
    total_reads_n = (sum(reads_n)) %>% round(1),
  ) %>%
  ungroup() %>%
  set_names(c("Batch", "Barcode ID", "Barcode classification", "Yield (Mbp)", "Total reads (n)")) %>%
  left_join(
    m %>% select(-sample_category),
    by = c("Batch" = "batch", "Barcode ID" = "barcode_id")
  )
  
datatable(seqsum_t2, filter = 'top')
```

**Column explanation**

* Batch: Sequencing run batch.
* Barcode ID: Barcode number from barcode01 to barcode96 as is standard output from MinKNOW.
* Barcode classification: Barcode has been classified as `used` for a sample in the metadata or if not classified as `unused`. Data in unused barcodes should in general not occur.
* Yield: Data yield assigned to a specific barcode.
* Total reads: Total reads assigned to a specific barcode.
* ...: Extra columns in the metadata sheet.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

## Appendix

---

&nbsp;
&nbsp;
&nbsp;
&nbsp;

### Negative control summary

The negative controls are key for the QC analysis as they indicate a data baseline and can hint a possible contamination and its source. Use at least 2 NC for each sequencing run.

This summary provides a list of negative controls used in the analysed runs.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Overall statistics
cs <-
  yf %>%
  filter(grepl("nc", str_to_lower(sample_name))) %>%
  transmute(
    batch,
    barcode_id,
    sample_name,
    yield_bp = (yield_bp/1000000) %>% round(1),
    genome_coverage = (100-n_count/ref_length*100) %>% round(1),
    classification,
    filter
  ) %>%
  mutate(
    color =
      case_when(
        filter == "NC_pass" ~ "mediumpurple",
        filter == "NC_fail" ~ "deeppink",
        T ~ "#F39B7FFF"
        )
  )

if(nrow(cs) != 0){
  cs %>%
    ungroup() %>%
    select(batch, sample_name, barcode_id, yield_bp, genome_coverage, classification, filter) %>%
    set_names(c("Group", "Sample Name", "Barcode ID", "Yield (Mbp)", "Genome coverage (%)", "Variant", "QC status")) %>%
    kbl() %>%
    kable_minimal(c("hover")) %>%
    column_spec(
      7,
      background = cs$color
    ) %>%
    kableExtra::footnote(
      general = "Negative control (NC) can either pass (NC_pass) or fail (NC_fail) in the filter. A NC fails if > 75% of the genome generates consensus, which requires > 20x coverage.", escape = FALSE 
    ) 
}
```

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, include=FALSE}
## amplicon visualization track
as <-
  acn %>%
  mutate(
    pool_id = ifelse(amplicon_id %% 2, 2, 1)
  ) %>%
  distinct_at(.vars = vars("batch", "amplicon_id", "start", "end", "pool_id")) %>%
  mutate(
    template_content = 
      case_when(
        T ~ "Present"
      )
  )
  
ap <- ggplot(
  as,
  aes(
    x = start,
    xend = end,
    y = as.factor(pool_id),
    yend = as.factor(pool_id)
  )
) +
  geom_segment(
    aes(color = template_content)
  ) +
  geom_text(
    aes(
      label = amplicon_id,
      x = (end - start)/2 + start,
      color = template_content
    ),
    vjust = 1,
    size = 2
  ) + 
  scale_color_manual(
    breaks = c("Missing", "Present"),
    values =  c("red", "black")
  ) +
  scale_x_continuous(
    limits = c(1, 30000)
  ) +
  facet_grid(rows = vars(batch)) +
  theme_classic() +
  theme(
    legend.position = "none",
    panel.border = element_rect(colour = "black", fill=NA, size=1),
    axis.text.x=element_blank(),
    axis.ticks.x=element_blank(),
    axis.text.y=element_blank(),
    axis.ticks.y=element_blank()
  ) +
  labs(
    y = NULL,
    x = "Genome position"
  )

```

### Negative control coverage

With sequencing there is always some data that is assigned to the wrong samples, and therefor we expect some data in the negative controls which we can use as a baseline. Data from the sequenced samples should exceed this baseline level with a defined factor (eg. 10x) for the samples to be trusted. 

Contamination is seen as distinct data patterns, which can point to potential sources. 


```{r message=FALSE, warning=FALSE, echo=FALSE}
# Control coverage plot
control_n <-
  filter(yf, sample_category == "control") %>%
  nrow()

if(control_n != 0){
acny <-
  acn %>%
  left_join(
    yf,
    .,
    by = c("batch", "barcode_id")
  )

pcc <- ggplot(
  acny %>%
    filter(sample_category == "control") %>%
    mutate(facet_id = paste(batch, barcode_id, sep = "-")),
  aes(
    x = start,
    xend = end,
    y = cov_mean,
    yend = cov_mean,
    color = cov_mean
  )
) +
  geom_segment(
    size=0.5
    ) +
  scale_y_log10() +
  scale_colour_viridis_c(
    trans = "log10",
    direction = 1,
    breaks = c(1, 20, 100, 1000, 10000),
    limits = c(1, NA),
    option = "turbo"
  ) +
  geom_hline(
    yintercept = 20,
    color = "red"
  ) +
  geom_text(
    data = cs %>%
    mutate(facet_id = paste(batch, barcode_id, sep = "-")),
    aes(
      x = ref_length/2,
      xend = NULL,
      y = 10000,
      yend = NULL,
      label = paste(
        "Sample name: ",
        sample_name,
        ", Yield: ",
        yield_bp,
        "Mbp, Genome Coverage: ",
        genome_coverage, 
        "%, Filter: ",
        filter
        )
    ),
    size = 2,
    color = cs$color
  ) +
  annotate(
    geom="text",
    x=0,
    y=30,
    label="20x",
    color="red"
  ) +
  facet_wrap(
    facets = vars(facet_id),
    ncol = 2, 
  ) +
  theme_classic() +
  theme(
    legend.position = "bottom",
    panel.border = element_rect(colour = "black", fill=NA, size=1)
  ) +
  labs(
    y = "Read coverage",
    x = NULL, 
    color = "Coverage"
  )

pcc
}
```

**Types of negative control contamination**

|   |   |
|---|---|
| < 75% coverage, < 20x coverage | Barcode demultiplexing bleed over or low template contamination probably in barcoding step (QC pass). |
| < 50% coverage, > 20x coverage | Low template contamination in pre PCR either from nucleotide extraction or PCR setup (QC pass). |
| < 75% coverage, > 20x coverage | Medium template contamination pre PCR either from nucleotide extraction or PCR setup (QC pass and caution). |
| > 75%, coverage, < 20x coverage | Low post PCR product contamination or barcode contamination typically from concentrated samples in the batch (QC pass and caution). |
| > 75%, coverage, > 20x coverage | High template or PCR product contamination from either nucleotide extraction, PCR setup, post PCR, barcode contamination (QC fail). |
| Some negative controls contaminated | Random contamination. |
| All negative controls contaminated | Reagent contamination or poor handling. |
|   |   |

&nbsp;
&nbsp;
&nbsp;
&nbsp;

### Unused barcode overview

Unused barcode information is available, when not all barcodes have been used and provides supporting information for the negative controls. In principle no data from unused barcodes should occur, but as with negative controls we expect a general bleed over that results in data also in unused barcodes. However, relative high data yield in unused barcodes indicate contamination.

This table contains a list of all unused barcodes producing data.

```{r message=FALSE, warning=FALSE, echo=FALSE}
datatable(
  seqsum_t2 %>%
    filter(`Barcode classification` == "Unused") %>%
    arrange(desc(`Yield (Mbp)`))
    )
```

### Sample absolute coverage overview

Coverage across the sample consensus genomes can help diagnose issues with the library preparation. The most typical issues observed are:

* Variant dependent amplicon dropout. Mutations in priming sites causes specific amplicons to drop-out.
* PCR dependent amplicon dropout. The PCR amplification has completely or partially crashed causing multiple amplicons to dropout. The cause can be many but common for them is inoptimal priming conditions.
* Pool dependent dropout. Same as above just for one of the two PCR reactions.
* Low template concentration. Random dropout at any level. Usually accompanied with low data yield.

The plot shows absolute coverage. Signals to look for are amplicon complete or partial dropouts which happens at a coverage of < 20 x.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, include=FALSE}
batch_n <-
  distinct(yf, batch) %>%
  nrow()
```

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.height=5*batch_n + 2, out.width = "100%"}
acny <-
  acn %>%
  left_join(
    yf,
    .,
    by = c("batch", "barcode_id")
  ) %>%
  filter(
    n_quality != "n_filter" | sample_category == "control"
  )

scp1 <- ggplot(
  acny,
  aes(
    x = (end - start)/2+start,
    y = cov_mean,
    color = filter,
    group = barcode_id
  )
) +
  geom_point(aes(x = jitter((end - start)/2+start, 0.4))) +
  geom_hline(
    yintercept = 20,
    color = "grey80"
  ) +
  annotate(
    geom="text",
    x=30000,
    y=30,
    label="20x",
    color="grey80"
  ) +
  facet_grid(
    factor(
      batch,
      levels = yfo)~.
      ) +
  scale_x_continuous(
    limits = c(1, 30000)
  ) +
  scale_y_log10() +
  scale_color_manual(
    values = yfc,
    breaks = yfl, 
    drop = FALSE
    )  +
  theme_classic() +
  theme(
    legend.position = "top",
    panel.border = element_rect(colour = "black", fill=NA, size=1)
  ) +
  labs(
    y = "Read coverage",
    x = NULL, 
    color = "Quality filter"
  )

scp1ap <- plot_grid(
  scp1,
  ap,
  ncol = 1,
  rel_heights = c(batch_n*2/(batch_n*2 + 1), 1/(batch_n*2 + 1)),
  align = 'v',
  axis = 'lr'
  )

scp1ap
```

**Coverage patterns**

NB: Plot is only showing genomes with < `r mq_n` Ns and the negative controls.

* `1-2` amplicon dropouts. Indicates mutations in priming sites or reagent issues. Typically the amplicon coverage is dividede in two distributions.
* `>2` amplicon dropouts. Usually indicates low template concentration or sub-optimal PCR reaction conditions. Sub-optimal causes: error in reagent mixing/dispensing, lid problems or machine temperature control problems.
* Amplicon pool coverage skew (every second amplicon has poor coverage). One of the PCR reactions failed or worked sub-optimally.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

### Sample normalized coverage overview

The plot shows normalized coverage. Signals to look for are amplicon complete or partial dropouts which typically happens at at  < 0.1 x normalized coverage. Poor normalized coverage does not necessarily lead to dropout, as it can be compensated by higher sequencing depth. However, data is wasted when amplicons have poor normalized coverage. The pattern of normalized coverage should stay the same across runs. If the pattern changes consistently this might indicate subtle changes to the library preparation or major shift in the variants sequenced. 

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.height=5*batch_n + 2, out.width = "100%"}
pcny <-
  pcn %>%
  left_join(
    yf,
    .,
    by = c("batch", "barcode_id")
  )  %>%
  filter(
    n_quality != "n_filter" | sample_category == "control"
  )

scp2 <- ggplot(
  pcny %>%
    group_by(barcode_id, batch) %>%
    sample_frac(0.05),
  aes(
    x = position,
    y = cov_norm,
    color = filter,
    group = barcode_id
  )
) +
  geom_line(
    alpha = 0.4
  ) +
  geom_hline(
    yintercept = 0.1,
    color = "grey80"
  ) +
  annotate(
    geom="text",
    x=30000,
    y=0.2,
    hjust = 0,
    label="0.1x",
    color="grey80"
  ) +
  facet_grid(
    factor(
      batch,
      levels = yfo)~.
      ) +
  scale_x_continuous(
    limits = c(1, 30000)
  ) +
  scale_y_log10() +
  scale_color_manual(
    values = yfc,
    breaks = yfl
    )  +
  theme_classic() +
  theme(
    legend.position = "top",
    panel.border = element_rect(colour = "black", fill=NA, size=1)
  ) +
  labs(
    y = "Read coverage",
    x = NULL, 
    color = "Quality filter"
  )

scp2ap <- plot_grid(
  scp2,
  ap,
  ncol = 1,
  rel_heights = c(batch_n*2/(batch_n*2 + 1), 1/(batch_n*2 + 1)), 
  align = 'v',
  axis = 'lr'
  )

scp2ap
```

**Coverage patterns**

NB: Plot is only showing genomes with < `r mq_n` Ns and the negative controls.

* `1-2` amplicon dropouts. Indicates mutations in priming sites or reagent issues. Typically the amplicon coverage is dividede in two distributions.
* `>2` amplicon dropouts. Usually indicates low template concentration or sub-optimal PCR reaction conditions. Possible causes: error in reagent mixing/dispensing, lid problems or machine temperature control problems.
* Amplicon pool coverage skew. One of the PCR reactions failed or worked sub-optimally.

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, include=FALSE}
pcny_sample <-
  yf %>%
  filter(filter %in% c("HQ", "MQ", "n_filter", "yield_filter")) %>%
  group_by(batch, filter) %>%
  slice_sample(n = 2, replace = F) %>%
  ungroup() %>%
  select(batch, barcode_id) %>%
  left_join(
    pcny,
    by = c("batch", "barcode_id")
  )

scp3 <- ggplot(
  pcny_sample,
  aes(
    x = position,
    y = cov_norm,
    color = filter,
    group = barcode_id
  )
) +
  geom_line(size=0.2) +
  geom_hline(
    yintercept = 0.1,
    color = "grey80"
  ) +
  annotate(
    geom="text",
    x=30000,
    y=0.2,
    hjust = 0,
    label="0.1x",
    color="grey80"
  ) +
    facet_grid(
    factor(
      batch,
      levels = yfo)~.
      ) +
  scale_y_log10() +
  scale_color_manual(
    values = yfc,
    breaks = yfl,
    drop = F
    ) +
  theme_classic() +
  theme(
    legend.position = "top",
    panel.border = element_rect(colour = "black", fill=NA, size=1)
  ) +
  labs(
    y = "Read coverage",
    x = NULL, 
    color = "Quality filter"
  )

scp3ap <- plot_grid(
  scp3,
  ap,
  ncol = 1,
  rel_heights = c(batch_n*2/(batch_n*2 + 1), 1/(batch_n*2 + 1)),
  align = 'v',
  axis = 'lr'
  )

scp3ap
```


### Overview of SNPs and ambiguous bases

SNPs pattern trees can help identify and troubleshoot mixed samples (samples contaminated by other samples). SNP patterns can also help identify systematic technical artefacts. Technical artefacts usually occur due to sub-optimal mapping around deletion in the amplicon terminals. A common problem is the same base(s) flanking a deletion as was deleted. When mapping to a reference these bases can map multiple places, resulting in erroneous consensus calling and insert artefacts. 

NB: Plot is only showing genomes with < 7000 Ns. 

&nbsp;
&nbsp;
&nbsp;
&nbsp;

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Determine SNP frequencies from HQ/MQ genomes
snv <- n %>%
  select(
    substitutions,
    deletions,
    insertions,
    missing_position,
    batch,
    barcode_id,
    mixed_position
  ) %>%
  apply(
    1,
    function(row){
      bind_rows(
        tibble(
          batch = row[5],
          barcode_id = row[6],
          snp_type = "sub",
          snp = str_split(row[1], ",") %>% unlist()
        ),
        tibble(
          batch = row[5],
          barcode_id = row[6],
          snp_type = "del",
          snp =
            if(!is.na(row[2])){
              str_split(row[2], ",") %>%
                unlist() %>%
                lapply(
                  function(m){
                    str_split(m, "-") %>%
                      unlist() %>%
                      as.integer() %>%
                      {seq(min(.), max(.), by = 1)} 
                  }
                ) %>%
                unlist() %>%
                paste(., "del", sep ="")           
            } else {
              NA
            }
        ),
        tibble(
          batch = row[5],
          barcode_id = row[6],
          snp_type = "ins",
          snp = str_split(row[3], ",") %>% unlist()
        ),
        tibble(
          batch = row[5],
          barcode_id = row[6],
          snp_type = "mix",
          snp =
          if(!is.na(row[7])){
            str_split(row[7], ",") %>%
              unlist() %>%
              lapply(
                function(m){
                  str_split(m, "-") %>%
                    unlist() %>%
                    as.integer() %>%
                    {seq(min(.), max(.), by = 1)}
                }
              ) %>%
              unlist() %>%
              paste(., "mix", sep ="")
          } else {
            NA
          }
        ),
        tibble(
          batch = row[5],
          barcode_id = row[6],
          snp_type = "miss",
          snp =
          if(!is.na(row[4])){
            str_split(row[4], ",") %>%
              unlist() %>%
              lapply(
                function(m){
                  str_split(m, "-") %>%
                    unlist() %>%
                    as.integer() %>%
                    {seq(min(.), max(.), by = 1)}
                }
              ) %>%
              unlist() %>%
              paste(., "N", sep ="")
          } else {
            NA
          }
        )
      )
    }
  ) %>%
  bind_rows(
  ) %>%
  mutate(
    position =  parse_number(snp),
    snp_var = 
      case_when(
        snp_type == "ins" ~ "ins",
        T ~ sub(".*[0-9]", "", snp)
      )
  ) %>%
  group_by(position) %>%
  filter(
    !is.na(snp)
  )
  


# Filter to most abundant SNP positions
snv_filter <-
  snv %>%
  left_join(
    n %>% select(batch, barcode_id, n_count),
    by = c("batch", "barcode_id")
  ) %>%
  filter(
    n_count <= 7000,
    snp_type != "miss"
  ) %>%
  group_by(
    position
  ) %>%
  summarise(
    n = n(),
    snps = paste(snp_var %>% unique(), collapse = ";")
  ) %>%
  filter(n > 2)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Plot tree for every batch
thl <- vector("list", length=length(tree) + 1)
figh <- vector("numeric", length=length(tree) + 1)
figh_tot <- 0
for (i in 1:length(tree)){
  # Batch name
  bn <- names(tree)[i]
  
  # Batch tree
  bt <- tree[[i]]
  
  # Prepare batch heatmap
  bth <- 
    snv %>%
    filter(
      position %in% snv_filter$position & batch == bn & barcode_id %in% bt$tip.label
    ) %>%
    select(barcode_id, position, snp_var) %>%
    group_by(barcode_id) %>%
    complete(position = snv_filter$position) %>%
    mutate(snp_var = ifelse(is.na(snp_var), "ref", snp_var)) %>%
    ungroup() %>%
    pivot_wider(names_from = "position", values_from = "snp_var", values_fill = "ref")
  
  bthf <- bth %>%
    select(colnames(bth)[-1] %>% as.numeric() %>% sort() %>% as.character()) %>%
    as.data.frame()
  
  rownames(bthf) <- bth$barcode_id
  
  # Prepare tree
  tm <- filter(yf, batch == bn & barcode_id %in% bt$tip.label) %>%
    select(-batch)
  
  
  p <- ggtree(bt) %<+% tm %>%
    {.} +
    geom_treescale() +
    geom_tiplab(
      align = F,
      linesize = .25,
      size = 2,
      aes(color = filter, label = paste(label, classification, sep = " ")),
      offset = 0.00016,
      fontface = "bold",
      hjust = 1.2, 
      vjust = 0
    ) +
    scale_color_manual(
      breaks = yfl,
      values = yfc,
      name = "Filter", 
      drop = F
    ) +
    guides(
      colour = guide_legend(override.aes = list(size = 4))
    ) +
    geom_tippoint(
      aes(color = factor(filter, levels = yfl)),
      size = 1
    ) +
    theme(
      legend.position = "bottom"
      )
  
  # Build plot
  if (length(snv_filter) > 0){
    
    tp1 <- gheatmap(
      p,
      bthf,
      colnames = ifelse(length(tree) == i, T, F), 
      colnames_angle = 90,
      hjust = 1,
      font.size = 2,
      width = 5
    ) +
      scale_fill_manual(
        values = c("#33a02c", "#1f78b4", "grey30", "#de2d26", "grey80", "orange", "purple", "greenyellow", "white"),  
        name = "Variant",
        breaks = c("A", "C", "G", "T", "N", "del", "ins", "mix", "ref")
      ) +
      theme(
        legend.position = "bottom"
      ) +
      {if(length(tree) == i)ggtree::vexpand(.1, -1)}
    
    thl[[i]] <-
      tp1 +
      theme(
        legend.position='none'
      )
    
    figh[[i]] <- ifelse(
      length(tree) == i,
      length(bt$tip.label)*0.2 + 1,
      length(bt$tip.label)*0.2
      )
    figh_tot <- figh_tot + figh[[i]]
  }
}

figh_tot <- figh_tot
figh[[i + 1]] <- 2 
thl[[i + 1]] <- get_legend(tp1)


cpqp1 <- plot_grid(
  plotlist = thl, 
  ncol = 1,
  align = 'v',
  axis = 'lr',
  rel_heights = figh,
  labels = names(tree),
  label_size = 7,
  label_x = 0,
  label_y = 1
)
```

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.height=figh_tot, out.width = "100%"}
cpqp1
```

**Types of patterns**

|   |   |
|---|---|
| >3 SNPS spread out across genome | Indicates contamination. SNP sites often correlates with SNPs in other genomes in the batch. |
| <=3 SNPS present in multiple genomes | Indicates technical error in consensus pipeline. Can sometimes be fixed by tweaking the bedfile. |
| Large sections of missing bases (N) | Amplicon drop-out. For more complete picture of amplicon dropout inspect the coverage overviews. |
| Consistent medium quality within specific clades of the tree | Indicates variant specific bias. Usually amplicon drop-out due to mutation in priming site. |

### Sample plate overview

Plate view is only applicable for samples prepared with barcode expansion kits where the barcodes (01 - 96) are placed in a plate column-wise. The benefit of the plate view is that inconsistencies in yield or quality can be put in context of the physical placement og the samples during library preparation.
  
  
**Yield plate view**

```{r message=FALSE, warning=FALSE, echo=FALSE, out.width = "80%"}
plate_view <- 
  tibble(
    barcode_id = paste("barcode", str_pad(1:96, 2, "left", 0), sep = "") %>% rep(batch_n),
    barcode_nr = 1:96 %>% rep(batch_n),
    row_id = rep(c("A", "B", "C", "D", "E", "F", "G", "H"), 12) %>% rep(batch_n),
    col_id = rep(1:12, each = 8) %>% rep(batch_n),
    batch = unique(yf$batch) %>% rep(each = 96)
  ) 
  

plate_yield <- 
  seqsum_t2 %>%
  filter(`Barcode ID` != "unclassified") %>%
  left_join(
    plate_view,
    by = c("Barcode ID" = "barcode_id", "Batch" = "batch")
  )

plate_meta <- 
  yf %>%
  left_join(
    plate_view,
    by = c("barcode_id", "batch")
  ) %>%
  mutate(
    filter_plot = 
      case_when(
        sample_category == "control" ~ "NC",
        T ~ "Used"
      ),
    Batch = batch
  )

ggplot(
  plate_yield,
  aes(
    x = as.integer(col_id),
    y = factor(row_id, levels = LETTERS[8:1]),
    fill = `Yield (Mbp)`
  )
) +
  geom_tile() +
  geom_tile(
    data = plate_view,
    color = "grey",
    fill = NA
  ) +
  geom_tile(
    data = plate_meta,
    aes(color = filter_plot),
    fill = NA
  ) +
  geom_text(aes(label = `Yield (Mbp)`), na.value = "NA", size = 2) +
  facet_wrap(facets = vars(Batch), ncol = 1) +
  scale_x_discrete("Columns", breaks = 1:12, limits = c(1:12)) +
  scale_fill_gradientn(
    colours = c("white", "#feb24c", "#f03b20"),
    values = c(0, 10/100, 50/100, 1),
    na.value = "#f03b20",
    breaks = c(1, 25, 50, 75, 100),
    limits = c(0, 100)
    ) +
  scale_color_manual(
    values = c("Black", "Red"),
    breaks = c("Used", "NC"),
    name = "Sample category"
  ) +
  labs(
    x = "Plate columns",
    y = "Plate rows"
  )
```

**QC plate view**

```{r message=FALSE, warning=FALSE, echo=FALSE, out.width = "80%"}
ggplot(
  plate_meta,
  aes(
    x = as.integer(col_id),
    y = factor(row_id, levels = LETTERS[8:1]),
    fill = filter
  )
) +
  geom_tile() +
  geom_tile(
    data = plate_view,
    color = "grey",
    fill = NA
  ) +
  geom_tile(
    data = plate_meta,
    color = "Black",
    fill = NA
  ) +
  facet_wrap(facets = vars(Batch), ncol = 1) +
  scale_x_discrete("Columns", breaks = 1:12, limits = c(1:12)) +
  scale_fill_manual(
    values = yfc,
    breaks = yfl,
    drop = FALSE
  ) +
  labs(
    x = "Plate columns",
    y = "Plate rows"
  )
```

### Concentration, yield QC plot

If template concentration is provided in the metadata this plot will be generated. Template concentration can be eg. known copy numbers from dilutions, Ct values or library concentrations. The column designation should be `template_conc`.

```{r message=FALSE, warning=FALSE, echo=FALSE, eval = ("template_conc" %in% colnames(m))}
ggplot(
  left_join(
    yf,
    seqsum_t2 %>% select(-sample_name, - template_conc),
    by = c("barcode_id" = "Barcode ID", "batch" = "Batch")
  ),
  aes(
    x = template_conc,
    y = `Yield (Mbp)`,
    color = filter
  )
) +
  geom_point() +
    facet_wrap(
      facets = vars(batch),
      ncol = 1,
      scales = "free"
      ) +
  scale_color_manual(
    values = yfc,
    breaks = yfl,
    drop = FALSE
  ) +
  labs(
    x = "Template concentration",
    y = "Yield (Mbp)"
  ) +
  theme_bw()

```



## Genome and metadata export

Export genomes and metadata based on QC filters. HQ/MQ genomes and metadata will be exported as `genome_pass.fa` and `metadata_pass.tsv`, where failed genomes and metadata will be exported as `genome_fail.fa` and `metadata_fail.tsv`.

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Export metadata for MQ/HQ genomes
me <- yf %>%
  filter(filter %in% c("HQ", "MQ")) %>%
  select(
    batch,
    barcode_id,
    sample_name,
    pango_lineage,
    scorpio_lineage
  )

write_tsv(me, "metadata_pass.tsv")

s[paste(me$batch, ".", me$barcode_id, sep = "")] %>%
  writeXStringSet("genome_pass.fa")

# Export metadata for failed genomes
mef <- yf %>%
  filter(!(filter %in% c("HQ", "MQ"))) %>%
  select(
    batch,
    barcode_id,
    sample_name,
    pango_lineage,
    scorpio_lineage
  )

write_tsv(mef, "metadata_fail.tsv")

s[paste(mef$batch, ".", mef$barcode_id, sep = "")] %>%
  writeXStringSet("genome_fail.fa")

tibble(`Data export` = list.files(getwd(), pattern = "genome_|metadata_", full.names = T)) %>%
  kbl() %>%
  kable_minimal(c("hover")) 
  
```

